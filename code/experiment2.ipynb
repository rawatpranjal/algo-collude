{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating experiments: 100%|██████████| 500/500 [3:41:11<00:00, 26.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'experiment2/data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "DEBUG = False\n",
    "def dprint(*args):\n",
    "    if DEBUG:\n",
    "        print(*args)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) Valuation with eta\n",
    "# --------------------------------------------------------------\n",
    "def get_valuation(eta, own_signal, others_signals):\n",
    "    \"\"\"\n",
    "    Valuation with affiliation parameter eta.\n",
    "    alpha(eta) = 1 - 0.5*eta\n",
    "    beta(eta)  = 0.5*eta\n",
    "    v_i = alpha(eta)*own_signal + beta(eta)*mean(others_signals)\n",
    "    \"\"\"\n",
    "    alpha = 1.0 - 0.5 * eta\n",
    "    beta = 0.5 * eta\n",
    "    return alpha * own_signal + beta * np.mean(others_signals)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Payoffs\n",
    "# --------------------------------------------------------------\n",
    "def get_payoffs(bids, valuations, auction_type):\n",
    "    \"\"\"\n",
    "    Calculate payoffs for multiple bidders.\n",
    "    First-price: winner pays own bid.\n",
    "    Second-price: winner pays second-highest bid.\n",
    "    Ties are broken randomly.\n",
    "    \"\"\"\n",
    "    n_bidders = len(bids)\n",
    "    rewards = np.zeros(n_bidders)\n",
    "    sorted_indices = np.argsort(bids)[::-1]\n",
    "    winner = sorted_indices[0]\n",
    "    highest_bid = bids[winner]\n",
    "\n",
    "    # Handle ties for the highest bid\n",
    "    tied_indices = [i for i in sorted_indices if bids[i] == highest_bid]\n",
    "    if len(tied_indices) > 1:\n",
    "        winner = random.choice(tied_indices)\n",
    "\n",
    "    second_highest_bid = bids[sorted_indices[1]] if len(bids) > 1 else highest_bid\n",
    "\n",
    "    if auction_type == \"first\":\n",
    "        rewards[winner] = valuations[winner] - highest_bid\n",
    "    else:  # second-price\n",
    "        rewards[winner] = valuations[winner] - second_highest_bid\n",
    "\n",
    "    return rewards, winner, highest_bid\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Q-learning update\n",
    "# --------------------------------------------------------------\n",
    "def qlearning_update(Q, s, a, r, s_next, alpha, gamma):\n",
    "    \"\"\"\n",
    "    Q-learning update for single state-action pair.\n",
    "    \"\"\"\n",
    "    old_q = Q[s, a]\n",
    "    best_future = np.max(Q[s_next])\n",
    "    Q[s, a] = old_q + alpha * (r + gamma * best_future - old_q)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Build state index\n",
    "# --------------------------------------------------------------\n",
    "def build_state(own_signal, median_opp_bid, past_winning_bid,\n",
    "                median_opp_past_bid_index, winner_bid_index_state,\n",
    "                n_val_bins, n_bid_bins):\n",
    "    \"\"\"\n",
    "    Build a state index based on:\n",
    "    - Own signal\n",
    "    - Median of opponents' bids (if included)\n",
    "    - Past winning bid (if included)\n",
    "    \"\"\"\n",
    "    median_idx = int(median_opp_bid) if median_opp_past_bid_index else 0\n",
    "    winner_idx = int(past_winning_bid) if winner_bid_index_state else 0\n",
    "    m_size = n_bid_bins if median_opp_past_bid_index else 1\n",
    "    w_size = n_bid_bins if winner_bid_index_state else 1\n",
    "\n",
    "    idx = own_signal\n",
    "    idx += n_val_bins * median_idx\n",
    "    idx += (n_val_bins * m_size) * winner_idx\n",
    "    dprint(f\"State index: {idx} (own_signal={own_signal}, median_idx={median_idx}, winner_idx={winner_idx})\")\n",
    "    return idx\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Run single experiment\n",
    "# --------------------------------------------------------------\n",
    "def run_experiment(eta, auction_type, alpha, gamma, episodes,\n",
    "                   init, exploration, asynchronous, n_bidders,\n",
    "                   median_opp_past_bid_index, winner_bid_index_state, seed=0):\n",
    "    \"\"\"\n",
    "    Run Q-learning for one experiment with optional state features.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    n_val_bins = 6\n",
    "    n_bid_bins = 6\n",
    "    m_size = n_bid_bins if median_opp_past_bid_index else 1\n",
    "    w_size = n_bid_bins if winner_bid_index_state else 1\n",
    "    n_states = n_val_bins * m_size * w_size\n",
    "\n",
    "    # Q-tables initialization\n",
    "    Q = np.random.rand(n_bidders, n_states, n_bid_bins) if init == \"random\" else np.zeros((n_bidders, n_states, n_bid_bins))\n",
    "\n",
    "    actions = np.linspace(0, 1, n_bid_bins)\n",
    "    eps_start, eps_end = 1.0, 0.01\n",
    "    decay_end = int(0.9 * episodes)\n",
    "\n",
    "    revenues = []\n",
    "    past_bids = np.zeros(n_bidders)\n",
    "    past_winner_bid = 0\n",
    "\n",
    "    def choose_action(Q_row, eps):\n",
    "        if exploration == \"boltzmann\":\n",
    "            ex = np.exp(Q_row)\n",
    "            probs = ex / np.sum(ex)\n",
    "            return np.random.choice(len(Q_row), p=probs)\n",
    "        else:  # e-greedy\n",
    "            if np.random.rand() < eps:\n",
    "                return np.random.randint(n_bid_bins)\n",
    "            return np.argmax(Q_row)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        eps = eps_start - (ep / decay_end) * (eps_start - eps_end) if ep < decay_end else eps_end\n",
    "\n",
    "        signals = np.random.randint(n_val_bins, size=n_bidders)\n",
    "        valuations = [get_valuation(eta, signals[i], np.delete(signals, i)) for i in range(n_bidders)]\n",
    "\n",
    "        states = [\n",
    "            build_state(signals[i], np.median(np.delete(past_bids, i)), past_winner_bid,\n",
    "                        median_opp_past_bid_index, winner_bid_index_state, n_val_bins, n_bid_bins)\n",
    "            for i in range(n_bidders)\n",
    "        ]\n",
    "\n",
    "        actions_taken = [choose_action(Q[i, states[i]], eps) for i in range(n_bidders)]\n",
    "        bids = [actions[a] for a in actions_taken]\n",
    "\n",
    "        rewards, winner, highest_bid = get_payoffs(bids, valuations, auction_type)\n",
    "\n",
    "        if asynchronous:\n",
    "            for i in range(n_bidders):\n",
    "                next_signals = np.random.randint(n_val_bins, size=n_bidders)\n",
    "                next_state = build_state(next_signals[i], np.median(np.delete(bids, i)), highest_bid,\n",
    "                                         median_opp_past_bid_index, winner_bid_index_state, n_val_bins, n_bid_bins)\n",
    "                qlearning_update(Q[i], states[i], actions_taken[i], rewards[i], next_state, alpha, gamma)\n",
    "        else:  # Synchronous (counterfactual updates)\n",
    "            for i in range(n_bidders):\n",
    "                state = states[i]\n",
    "                for alt_action in range(n_bid_bins):\n",
    "                    counterfactual_bids = bids.copy()\n",
    "                    counterfactual_bids[i] = actions[alt_action]\n",
    "                    counterfactual_rewards, _, _ = get_payoffs(counterfactual_bids, valuations, auction_type)\n",
    "                    max_next_q = np.max(Q[i, state])\n",
    "                    Q[i, state, alt_action] = (1 - alpha) * Q[i, state, alt_action] + alpha * (counterfactual_rewards[i] + gamma * max_next_q)\n",
    "\n",
    "        revenues.append(max(bids))\n",
    "        past_bids = bids\n",
    "        past_winner_bid = highest_bid\n",
    "\n",
    "    avg_rev_last_1000 = np.mean(revenues[-1000:]) if len(revenues) >= 1000 else np.mean(revenues)\n",
    "    regrets = [1.0 - r for r in revenues]\n",
    "    avg_regret_of_seller = np.mean(regrets)\n",
    "\n",
    "    time_to_converge = episodes\n",
    "    rolling_avg = pd.Series(revenues).rolling(window=1000, min_periods=1).mean()\n",
    "    lower_bound, upper_bound = 0.95 * avg_rev_last_1000, 1.05 * avg_rev_last_1000\n",
    "    for t in range(len(rolling_avg)):\n",
    "        if lower_bound <= rolling_avg.iloc[t] <= upper_bound:\n",
    "            time_to_converge = t\n",
    "            break\n",
    "\n",
    "    return avg_rev_last_1000, time_to_converge, avg_regret_of_seller\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Main experiment loop\n",
    "# --------------------------------------------------------------\n",
    "def main_experiment(K=30):\n",
    "    \"\"\"\n",
    "    Generate data for K experiments with random parameter draws.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    auction_type_options = [\"first\", \"second\"]\n",
    "    init_options = [\"random\", \"zeros\"]\n",
    "    exploration_options = [\"egreedy\", \"boltzmann\"]\n",
    "\n",
    "    for seed in trange(K, desc=\"Generating experiments\"):\n",
    "        eta = random.uniform(0.0, 1.0)\n",
    "        alpha = random.uniform(0.001, 0.1)\n",
    "        gamma = random.uniform(0.0, 0.99)\n",
    "        episodes = int(random.uniform(50_000, 250_000))\n",
    "        auction_type = random.choice(auction_type_options)\n",
    "        init = random.choice(init_options)\n",
    "        exploration = random.choice(exploration_options)\n",
    "        asynchronous = random.choice([0, 1])\n",
    "        n_bidders = random.choice([2, 4, 6])\n",
    "        median_opp_past_bid_index = random.choice([False, True])\n",
    "        winner_bid_index_state = random.choice([False, True])\n",
    "\n",
    "        avg_rev_last_1000, time_to_converge, avg_regret_of_seller = run_experiment(\n",
    "            eta, auction_type, alpha, gamma, episodes, init, exploration,\n",
    "            asynchronous, n_bidders, median_opp_past_bid_index, winner_bid_index_state, seed\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"eta\": eta,\n",
    "            \"alpha\": alpha,\n",
    "            \"gamma\": gamma,\n",
    "            \"episodes\": episodes,\n",
    "            \"auction_type\": auction_type,\n",
    "            \"init\": init,\n",
    "            \"exploration\": exploration,\n",
    "            \"asynchronous\": asynchronous,\n",
    "            \"n_bidders\": n_bidders,\n",
    "            \"median_opp_past_bid_index\": median_opp_past_bid_index,\n",
    "            \"winner_bid_index_state\": winner_bid_index_state,\n",
    "            \"avg_rev_last_1000\": avg_rev_last_1000,\n",
    "            \"time_to_converge\": time_to_converge,\n",
    "            \"avg_regret_of_seller\": avg_regret_of_seller\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) Run and save data\n",
    "# --------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"experiment2\", exist_ok=True)\n",
    "\n",
    "    df = main_experiment(K=500)\n",
    "    csv_path = \"experiment2/data.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Data generation complete. Saved to '{csv_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inference for Outcome: avg_rev_last_1000 ==========\n",
      "========== ATE Results for avg_rev_last_1000 ==========\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "D  0.003722  0.026663  0.139603  0.888974 -0.048536  0.055981\n",
      "Generating GATE plots for avg_rev_last_1000...\n",
      "GATE plots for avg_rev_last_1000 saved to: experiment2/gate_plots_avg_rev_last_1000.png\n",
      "Generating CATE plots for avg_rev_last_1000...\n",
      "CATE plots for avg_rev_last_1000 saved to: experiment2/cate_plots_avg_rev_last_1000.png\n",
      "\n",
      "========== Inference for Outcome: time_to_converge ==========\n",
      "========== ATE Results for time_to_converge ==========\n",
      "           coef       std err         t    P>|t|         2.5 %        97.5 %\n",
      "D  19365.333333  15396.717712  1.257757  0.20848 -10811.678862  49542.345529\n",
      "Generating GATE plots for time_to_converge...\n",
      "GATE plots for time_to_converge saved to: experiment2/gate_plots_time_to_converge.png\n",
      "Generating CATE plots for time_to_converge...\n",
      "CATE plots for time_to_converge saved to: experiment2/cate_plots_time_to_converge.png\n",
      "\n",
      "========== Inference for Outcome: avg_regret_of_seller ==========\n",
      "========== ATE Results for avg_regret_of_seller ==========\n",
      "       coef   std err         t     P>|t|    2.5 %    97.5 %\n",
      "D  0.005753  0.022808  0.252238  0.800857 -0.03895  0.050456\n",
      "Generating GATE plots for avg_regret_of_seller...\n",
      "GATE plots for avg_regret_of_seller saved to: experiment2/gate_plots_avg_regret_of_seller.png\n",
      "Generating CATE plots for avg_regret_of_seller...\n",
      "CATE plots for avg_regret_of_seller saved to: experiment2/cate_plots_avg_regret_of_seller.png\n",
      "\n",
      "Inference complete. All results saved in 'experiment2/' folder.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# DoubleML\n",
    "import doubleml as dml\n",
    "from doubleml import DoubleMLData, DoubleMLIRM\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "# For spline expansions (CATE)\n",
    "import patsy\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 1) Setup: Create output directory\n",
    "    # ------------------------------------------------------------------------------\n",
    "    os.makedirs(\"experiment2\", exist_ok=True)\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 2) Load Experiment 2 Data\n",
    "    # ------------------------------------------------------------------------------\n",
    "    df = pd.read_csv(\"experiment2/data.csv\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 3) Treatment and Covariates\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Define treatment\n",
    "    df[\"D\"] = (df[\"auction_type\"] == \"second\").astype(int)\n",
    "\n",
    "    # Continuous covariates\n",
    "    cont_cols = [\"eta\", \"alpha\", \"gamma\", \"episodes\"]\n",
    "\n",
    "    # Binary covariates\n",
    "    df[\"init\"] = (df[\"init\"] == \"random\").astype(int)\n",
    "    df[\"exploration\"] = (df[\"exploration\"] == \"egreedy\").astype(int)\n",
    "    df[\"median_opp_past_bid_index\"] = df[\"median_opp_past_bid_index\"].astype(int)\n",
    "    df[\"winner_bid_index_state\"] = df[\"winner_bid_index_state\"].astype(int)\n",
    "    df[\"asynchronous\"] = df[\"asynchronous\"].astype(int)\n",
    "\n",
    "    binary_cols = [\"init\", \"exploration\", \"median_opp_past_bid_index\", \"winner_bid_index_state\", \"asynchronous\"]\n",
    "\n",
    "    # All covariates\n",
    "    X_cols = cont_cols + binary_cols\n",
    "\n",
    "    # Define outcomes\n",
    "    outcomes = [\"avg_rev_last_1000\", \"time_to_converge\", \"avg_regret_of_seller\"]\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 4) Loop Over Outcomes\n",
    "    # ------------------------------------------------------------------------------\n",
    "    for outcome in outcomes:\n",
    "        print(f\"\\n========== Inference for Outcome: {outcome} ==========\")\n",
    "\n",
    "        # Define current outcome\n",
    "        df[\"Y\"] = df[outcome]\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 5) Prepare DoubleML Data and Model\n",
    "        # ------------------------------------------------------------------------------\n",
    "        dml_data = DoubleMLData(\n",
    "            df,\n",
    "            y_col=\"Y\",\n",
    "            d_cols=\"D\",\n",
    "            x_cols=X_cols\n",
    "        )\n",
    "\n",
    "        # Define learners\n",
    "        ml_g = LGBMRegressor(verbose=-1, random_state=123)\n",
    "        ml_m = LGBMClassifier(verbose=-1, random_state=123)\n",
    "\n",
    "        # Initialize DoubleML IRM Model\n",
    "        dml_irm = DoubleMLIRM(\n",
    "            dml_data,\n",
    "            ml_g=ml_g,\n",
    "            ml_m=ml_m,\n",
    "            n_folds=3,\n",
    "            score=\"ATE\"\n",
    "        )\n",
    "\n",
    "        # Fit the model\n",
    "        dml_irm.fit()\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 6) Print and Save ATE Results\n",
    "        # ------------------------------------------------------------------------------\n",
    "        print(f\"========== ATE Results for {outcome} ==========\")\n",
    "        print(dml_irm.summary)\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 7) GATEs for Binary Covariates\n",
    "        # ------------------------------------------------------------------------------\n",
    "        print(f\"Generating GATE plots for {outcome}...\")\n",
    "        n_bin = len(binary_cols)\n",
    "        nrows_gate = int(np.ceil(n_bin / 3))  # up to 3 columns\n",
    "        ncols_gate = min(n_bin, 3)\n",
    "\n",
    "        fig_gate, axes_gate = plt.subplots(nrows=nrows_gate, ncols=ncols_gate,\n",
    "                                           figsize=(5 * ncols_gate, 4 * nrows_gate))\n",
    "\n",
    "        if n_bin == 1:\n",
    "            axes_gate = np.array([axes_gate])\n",
    "\n",
    "        for i, bin_col in enumerate(binary_cols):\n",
    "            groups_df = df[[bin_col]].astype(\"category\")\n",
    "            gate_obj = dml_irm.gate(groups=groups_df)\n",
    "            ci_95_gate = gate_obj.confint(level=0.95)\n",
    "\n",
    "            effects = ci_95_gate[\"effect\"]\n",
    "            lower_95 = ci_95_gate[\"2.5 %\"]\n",
    "            upper_95 = ci_95_gate[\"97.5 %\"]\n",
    "\n",
    "            ax = axes_gate.flatten()[i] if n_bin > 1 else axes_gate[0]\n",
    "            x_positions = [0, 1]\n",
    "            ax.errorbar(\n",
    "                x_positions, effects,\n",
    "                yerr=[effects - lower_95, upper_95 - effects],\n",
    "                fmt=\"o\", capsize=5\n",
    "            )\n",
    "            ax.set_title(f\"GATE: {bin_col}\")\n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels([f\"{bin_col}=0\", f\"{bin_col}=1\"])\n",
    "            ax.set_ylabel(\"Estimated GATE\")\n",
    "\n",
    "        fig_gate.tight_layout()\n",
    "        gate_plot_path = os.path.join(\"experiment2\", f\"gate_plots_{outcome}.png\")\n",
    "        fig_gate.savefig(gate_plot_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig_gate)\n",
    "        print(f\"GATE plots for {outcome} saved to: {gate_plot_path}\")\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 8) CATEs for Continuous Covariates\n",
    "        # ------------------------------------------------------------------------------\n",
    "        print(f\"Generating CATE plots for {outcome}...\")\n",
    "        n_cont = len(cont_cols)\n",
    "        nrows_cate = int(np.ceil(n_cont / 3))\n",
    "        ncols_cate = min(n_cont, 3)\n",
    "\n",
    "        fig_cate, axes_cate = plt.subplots(nrows=nrows_cate, ncols=ncols_cate,\n",
    "                                           figsize=(5 * ncols_cate, 4 * nrows_cate))\n",
    "\n",
    "        if n_cont == 1:\n",
    "            axes_cate = np.array([axes_cate])\n",
    "\n",
    "        for i, cont_col in enumerate(cont_cols):\n",
    "            design_matrix = patsy.dmatrix(f\"bs({cont_col}, df=5, degree=2)\", df)\n",
    "            spline_basis = pd.DataFrame(design_matrix)\n",
    "\n",
    "            cate_obj = dml_irm.cate(basis=spline_basis)\n",
    "            ci_95_cate = cate_obj.confint(basis=spline_basis, level=0.95)\n",
    "\n",
    "            effects_cate = ci_95_cate[\"effect\"].values\n",
    "            lower_95_cate = ci_95_cate[\"2.5 %\"].values\n",
    "            upper_95_cate = ci_95_cate[\"97.5 %\"].values\n",
    "\n",
    "            x_values = df[cont_col].values\n",
    "            idx_sort = np.argsort(x_values)\n",
    "\n",
    "            x_sorted = x_values[idx_sort]\n",
    "            eff_sorted = effects_cate[idx_sort]\n",
    "            low_sorted = lower_95_cate[idx_sort]\n",
    "            up_sorted = upper_95_cate[idx_sort]\n",
    "\n",
    "            ax_cate = axes_cate.flatten()[i] if n_cont > 1 else axes_cate[0]\n",
    "            ax_cate.plot(x_sorted, eff_sorted, label=\"CATE\")\n",
    "            ax_cate.fill_between(x_sorted, low_sorted, up_sorted,\n",
    "                                 alpha=0.2, label=\"95% CI\")\n",
    "            ax_cate.set_title(f\"CATE: {cont_col}\")\n",
    "            ax_cate.set_xlabel(cont_col)\n",
    "            ax_cate.set_ylabel(\"Estimated Treatment Effect\")\n",
    "            ax_cate.legend()\n",
    "\n",
    "        fig_cate.tight_layout()\n",
    "        cate_plot_path = os.path.join(\"experiment2\", f\"cate_plots_{outcome}.png\")\n",
    "        fig_cate.savefig(cate_plot_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig_cate)\n",
    "        print(f\"CATE plots for {outcome} saved to: {cate_plot_path}\")\n",
    "\n",
    "    print(\"\\nInference complete. All results saved in 'experiment2/' folder.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
