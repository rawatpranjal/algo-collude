{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "DEBUG = False\n",
    "def dprint(*args):\n",
    "    if DEBUG:\n",
    "        print(*args)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) Valuation with eta (normalized)\n",
    "# --------------------------------------------------------------\n",
    "def get_valuation(eta, own_signal, others_signals):\n",
    "    alpha = 1.0 - 0.5 * eta\n",
    "    beta = 0.5 * eta\n",
    "    return alpha * own_signal + beta * np.mean(others_signals)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Payoffs\n",
    "# --------------------------------------------------------------\n",
    "def get_payoffs(bids, valuations, auction_type):\n",
    "    n_bidders = len(bids)\n",
    "    rewards = np.zeros(n_bidders)\n",
    "    sorted_indices = np.argsort(bids)[::-1]\n",
    "    winner = sorted_indices[0]\n",
    "    highest_bid = bids[winner]\n",
    "\n",
    "    # Tie-breaking\n",
    "    tied_indices = [i for i in sorted_indices if bids[i] == highest_bid]\n",
    "    if len(tied_indices) > 1:\n",
    "        winner = random.choice(tied_indices)\n",
    "\n",
    "    second_highest_bid = bids[sorted_indices[1]] if len(bids) > 1 else highest_bid\n",
    "\n",
    "    if auction_type == \"first\":\n",
    "        rewards[winner] = valuations[winner] - highest_bid\n",
    "    else:\n",
    "        rewards[winner] = valuations[winner] - second_highest_bid\n",
    "\n",
    "    return rewards, winner, highest_bid\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Bandit helpers: UCB and Linear (Contextual)\n",
    "# --------------------------------------------------------------\n",
    "class UCBBandit:\n",
    "    def __init__(self, n_actions, c):\n",
    "        self.n_actions = n_actions\n",
    "        self.c = c\n",
    "        self.counts = np.zeros(n_actions)\n",
    "        self.sums = np.zeros(n_actions)\n",
    "        self.total_pulls = 0\n",
    "\n",
    "    def select_action(self):\n",
    "        # If any action not tried, pick it\n",
    "        untried = np.where(self.counts == 0)[0]\n",
    "        if len(untried) > 0:\n",
    "            return np.random.choice(untried)\n",
    "        # Otherwise pick UCB\n",
    "        avg = self.sums / self.counts\n",
    "        ucb = avg + self.c * np.sqrt(np.log(self.total_pulls) / self.counts)\n",
    "        return np.argmax(ucb)\n",
    "\n",
    "    def update(self, action, reward):\n",
    "        self.counts[action] += 1\n",
    "        self.sums[action] += reward\n",
    "        self.total_pulls += 1\n",
    "\n",
    "class LinearContextualBandit:\n",
    "    def __init__(self, n_actions, context_dim, c, reg=1.0):\n",
    "        self.n_actions = n_actions\n",
    "        self.context_dim = context_dim\n",
    "        self.c = c\n",
    "        self.reg = reg\n",
    "        # For each action, maintain A (X'X + regI) and b (X'y)\n",
    "        self.A = [reg * np.eye(context_dim) for _ in range(n_actions)]\n",
    "        self.b = [np.zeros((context_dim,)) for _ in range(n_actions)]\n",
    "\n",
    "    def select_action(self, context):\n",
    "        # For each action, estimate reward = theta' * x + bonus\n",
    "        # theta = A_inv * b\n",
    "        mu = []\n",
    "        for a in range(self.n_actions):\n",
    "            A_inv = np.linalg.inv(self.A[a])\n",
    "            theta_hat = A_inv @ self.b[a]\n",
    "            mean_est = theta_hat @ context\n",
    "            var_est = context.T @ A_inv @ context\n",
    "            bonus = self.c * np.sqrt(var_est)\n",
    "            mu.append(mean_est + bonus)\n",
    "        return np.argmax(mu)\n",
    "\n",
    "    def update(self, action, context, reward):\n",
    "        # A[a] += x*x', b[a] += x*r\n",
    "        self.A[action] += np.outer(context, context)\n",
    "        self.b[action] += context * reward\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Run bandit experiment (replaces Q-learning)\n",
    "# --------------------------------------------------------------\n",
    "def run_bandit_experiment(\n",
    "    eta, auction_type, bandit_type, c, n_bidders,\n",
    "    n_val_bins=6, n_bid_bins=6, seed=0, max_rounds=200_000,\n",
    "    conv_window=1000, conv_thresh=1e-3\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Discretized bid actions\n",
    "    actions = np.linspace(0, 1, n_bid_bins)\n",
    "\n",
    "    # Initialize bandits\n",
    "    if bandit_type == \"ucb\":\n",
    "        bandits = [UCBBandit(n_bid_bins, c) for _ in range(n_bidders)]\n",
    "    else:  # 'contextual'\n",
    "        # context_dim = 3 (own_signal, last_median_bid, last_winning_bid)\n",
    "        bandits = [LinearContextualBandit(n_bid_bins, 3, c) for _ in range(n_bidders)]\n",
    "\n",
    "    revenues = []\n",
    "    past_bids = np.zeros(n_bidders)\n",
    "    past_winner_bid = 0.0\n",
    "\n",
    "    def get_context(bidder_signal, median_bid, winner_bid):\n",
    "        return np.array([bidder_signal, median_bid, winner_bid])\n",
    "\n",
    "    time_to_converge = max_rounds\n",
    "    for r in range(max_rounds):\n",
    "        # Signals in [0, 1]\n",
    "        signals = np.random.randint(n_val_bins, size=n_bidders) / (n_val_bins - 1)\n",
    "\n",
    "        # Valuations\n",
    "        valuations = [get_valuation(eta, signals[i], np.delete(signals, i)) \n",
    "                      for i in range(n_bidders)]\n",
    "\n",
    "        # Each bidder picks bid\n",
    "        chosen_bids = []\n",
    "        for i in range(n_bidders):\n",
    "            context = get_context(signals[i], np.median(np.delete(past_bids, i)), past_winner_bid)\n",
    "            if bandit_type == \"ucb\":\n",
    "                a = bandits[i].select_action()\n",
    "            else:\n",
    "                a = bandits[i].select_action(context)\n",
    "            chosen_bids.append((i, a, context))\n",
    "\n",
    "        bids = [actions[a[1]] for a in chosen_bids]\n",
    "        rewards, winner, highest_bid = get_payoffs(bids, valuations, auction_type)\n",
    "\n",
    "        # Update bandits\n",
    "        for (i, a, context) in chosen_bids:\n",
    "            bandit_reward = rewards[i]\n",
    "            if bandit_type == \"ucb\":\n",
    "                bandits[i].update(a, bandit_reward)\n",
    "            else:\n",
    "                bandits[i].update(a, context, bandit_reward)\n",
    "\n",
    "        # Track revenue (max bid)\n",
    "        revenues.append(np.max(bids))\n",
    "        # Update memory\n",
    "        past_bids = np.array(bids)\n",
    "        past_winner_bid = highest_bid\n",
    "\n",
    "        # Convergence check\n",
    "        if r >= conv_window:\n",
    "            recent = revenues[-conv_window:]\n",
    "            if np.std(recent) < conv_thresh:\n",
    "                time_to_converge = r\n",
    "                break\n",
    "\n",
    "    avg_rev = np.mean(revenues[-conv_window:])\n",
    "    return avg_rev, time_to_converge, np.mean(1.0 - np.array(revenues))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Main experiment loop\n",
    "# --------------------------------------------------------------\n",
    "def main_experiment(K=50):\n",
    "    results = []\n",
    "    auction_type_options = [\"first\", \"second\"]\n",
    "    bandit_type_options = [\"ucb\", \"contextual\"]\n",
    "\n",
    "    for seed in trange(K, desc=\"Generating experiments\"):\n",
    "        eta = random.uniform(0.0, 1.0)\n",
    "        c = random.uniform(0.01, 2.0)  # exploration parameter\n",
    "        n_bidders = random.choice([2, 4, 6])\n",
    "        bandit_type = random.choice(bandit_type_options)\n",
    "        auction_type = random.choice(auction_type_options)\n",
    "\n",
    "        avg_rev, time_to_converge, avg_regret = run_bandit_experiment(\n",
    "            eta=eta,\n",
    "            auction_type=auction_type,\n",
    "            bandit_type=bandit_type,\n",
    "            c=c,\n",
    "            n_bidders=n_bidders,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"eta\": eta,\n",
    "            \"c\": c,\n",
    "            \"auction_type\": auction_type,\n",
    "            \"bandit_type\": bandit_type,\n",
    "            \"n_bidders\": n_bidders,\n",
    "            \"avg_rev\": avg_rev,\n",
    "            \"time_to_converge\": time_to_converge,\n",
    "            \"avg_regret_seller\": avg_regret\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Run and save data\n",
    "# --------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"experiment3\", exist_ok=True)\n",
    "    df = main_experiment(K=30)\n",
    "    csv_path = \"experiment3/data.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Data generation complete. Saved to '{csv_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
